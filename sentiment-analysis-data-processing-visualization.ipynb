{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Sentiment Analysis: Data Processing, Visualization, and Model Evaluation"]},{"cell_type":"markdown","metadata":{},"source":["# ðŸ“Œ Introduction  \n","\n","In this study, we analyzed a text-based dataset with sentiment labels, following three main steps: **data preprocessing**, **visualization**, and **model testing**.  \n","\n","First, we cleaned and normalized the data to ensure consistency. Then, we explored the dataset using visualizations such as boxplots, bar charts,lineplot and scatterplot to identify trends and relationships. Finally, we tested different machine learning models for sentiment classification, comparing their accuracy and performance.  \n","\n","With these steps completed, we now evaluate the results and potential improvements.  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import networkx as nx\n","import nltk\n","from collections import Counter\n","from nltk.tokenize import word_tokenize\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Load the dataset\n","file_path = 'sentimentdataset.csv'\n","df = pd.read_csv(file_path)"]},{"cell_type":"markdown","metadata":{},"source":["## Data Overview"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Data Cleaning\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df['Sentiment'] = df['Sentiment'].str.strip()\n","df['Platform'] = df['Platform'].str.strip().str.capitalize()\n","\n","# Drop unnecessary columns\n","df.drop(columns=['Unnamed: 0', 'Unnamed: 0.1'], inplace=True)\n","\n","# Check for missing values\n","df.isnull().sum()"]},{"cell_type":"markdown","metadata":{},"source":["# Exploratory Data Analysis"]},{"cell_type":"markdown","metadata":{},"source":["## Sentiment Distribution, only the top 20 most used sentiments for improve the visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["sns.set_style(\"whitegrid\")\n","# Get the top 20 most used sentiments\n","top_20_sentiments = df[\"Sentiment\"].value_counts().nlargest(20).index\n","filtered_df = df[df[\"Sentiment\"].isin(top_20_sentiments)]\n","\n","# Plot\n","sns.set_style(\"whitegrid\")\n","plt.figure(figsize=(10, 5))\n","\n","sns.countplot(x=filtered_df[\"Sentiment\"], palette=\"viridis\", order=top_20_sentiments)\n","plt.title(\"Sentiment Distribution (Top 20)\")\n","plt.xticks(rotation=45, ha=\"right\")  # Rotate labels for better visibility\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Posts by Platform"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize=(10, 5))\n","\n","sns.countplot(x=df[\"Platform\"], palette=\"pastel\")\n","plt.title(\"Posts by Platform\")\n","plt.xticks(rotation=45, ha=\"right\")\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Likes by Sentiment (Positive and Negative)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Filter sentiments \"Positive\" and \"Negative\"\n","df_filtered = df[df['Sentiment'].isin(['Positive', 'Negative'])]\n","\n","plt.figure(figsize=(8, 6))\n","sns.boxplot(x='Sentiment', y='Likes', data=df_filtered, palette={'Positive': 'green', 'Negative': 'red'})\n","\n","plt.title('Likes distribution per Sentiment')\n","plt.xlabel('Sentiment')\n","plt.ylabel('Likes')\n","\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Average Likes per hour"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize=(10,6))\n","sns.lineplot(x=df['Hour'], y=df['Likes'], estimator='mean', ci=None)\n","plt.title(\"Average Likes per hour\")\n","plt.xlabel(\"Hour\")\n","plt.ylabel(\"Average Likes per hour\")\n","plt.xticks(range(0, 24))\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Average Likes for each Plataform"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize=(8,6))\n","sns.barplot(x=df['Platform'], y=df['Likes'], estimator='mean', palette=\"Set2\")\n","plt.title(\"Average Likes for each Plataform\")\n","plt.xlabel(\"Plataform\")\n","plt.ylabel(\"Average Likes\")\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Average Likes per Sentiment (Top 20)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize=(10, 5))\n","\n","sns.barplot(\n","    x=filtered_df[\"Sentiment\"], \n","    y=filtered_df[\"Likes\"], \n","    palette=\"coolwarm\", \n","    order=top_20_sentiments\n",")\n","plt.title(\"Average Likes per Sentiment (Top 20)\")\n","plt.xticks(rotation=45, ha=\"right\")\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Correlation between Retweets and Likes"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize=(8, 6))\n","\n","sns.scatterplot(x=df[\"Retweets\"], y=df[\"Likes\"], hue=df[\"Sentiment\"], palette=\"Dark2\", s=100)\n","plt.title(\"Correlation between Retweets and Likes\")\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Graph Connecting Words with Sentiments\n","\n","- **Red nodes** represent the 20 most common sentiments.  \n","- **Blue nodes** represent the 50 most frequently used words.  \n","- An **edge** between a blue node and a red node indicates a strong relationship between the word and the sentiment.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Ensure you have the necessary NLTK data\n","nltk.download('punkt')\n","# Create a NetworkX graph\n","G = nx.Graph()\n","\n","# Tokenize words from the \"Text\" column and count occurrences\n","word_sentiment_edges = []\n","word_counts = Counter()\n","\n","for _, row in filtered_df.iterrows():\n","    words = word_tokenize(row[\"Text\"].lower())  # Tokenize and convert to lowercase\n","    sentiment = row[\"Sentiment\"]\n","    \n","    for word in words:\n","        if word.isalpha():  # Only keep alphabetic words (remove punctuation, numbers)\n","            word_counts[word] += 1\n","            word_sentiment_edges.append((word, sentiment))\n","\n","# Select the **most frequent words** to avoid clutter (Top 50 words)\n","top_words = [word for word, count in word_counts.most_common(50)]\n","\n","# Add nodes (Sentiments and Words)\n","for sentiment in top_20_sentiments:\n","    G.add_node(sentiment, color=\"red\", size=800)  # Sentiments in Red\n","\n","for word in top_words:\n","    G.add_node(word, color=\"blue\", size=300)  # Words in Blue\n","\n","# Add edges only if the word is in the top 50\n","for word, sentiment in word_sentiment_edges:\n","    if word in top_words:\n","        G.add_edge(word, sentiment)\n","\n","# Extract node colors and sizes\n","node_colors = [G.nodes[node][\"color\"] for node in G.nodes()]\n","node_sizes = [G.nodes[node][\"size\"] for node in G.nodes()]\n","\n","# Draw the graph\n","plt.figure(figsize=(12, 8))\n","pos = nx.spring_layout(G, seed=42)  # Layout for visualization\n","\n","nx.draw(\n","    G, pos, with_labels=True, node_color=node_colors, \n","    node_size=node_sizes, edge_color=\"gray\", font_size=10, font_weight=\"bold\"\n",")\n","\n","plt.title(\"Word-Sentiment Relationship Graph\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Sentiment Prediction"]},{"cell_type":"markdown","metadata":{},"source":["## Naive Bayes classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Prepare data for modeling\n","X = df['Text']\n","y = df['Sentiment']\n","\n","# Split the data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Vectorize the text data\n","vectorizer = CountVectorizer()\n","X_train_vec = vectorizer.fit_transform(X_train)\n","X_test_vec = vectorizer.transform(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Train a Naive Bayes classifier\n","model = MultinomialNB()\n","model.fit(X_train_vec, y_train)\n","\n","# Make predictions\n","y_pred = model.predict(X_test_vec)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Accuracy score\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy:.2f}')\n","\n","# Classification report\n","print(classification_report(y_test, y_pred))\n","\n","# Confusion matrix\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n","plt.title('Confusion Matrix')\n","plt.xlabel('Predicted')\n","plt.ylabel('Actual')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## TF-IDF + Logistic Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# TF-IDF Vectorization\n","vectorizer = TfidfVectorizer()\n","X_train_vec = vectorizer.fit_transform(X_train)\n","X_test_vec = vectorizer.transform(X_test)\n","\n","# Train Logistic Regression\n","model = LogisticRegression()\n","model.fit(X_train_vec, y_train)\n","\n","# Evaluate\n","y_pred = model.predict(X_test_vec)\n","print(f'Logistic Regression Accuracy: {accuracy:.2f}')\n","print(classification_report(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{},"source":["## Random Forest"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Train Random Forest\n","model = RandomForestClassifier(n_estimators=100, random_state=42)\n","model.fit(X_train_vec, y_train)\n","\n","# Predictions\n","y_pred = model.predict(X_test_vec)\n","\n","# Accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Random Forest Accuracy: {accuracy:.2f}')\n","# Classification report\n","print(classification_report(y_test, y_pred))\n"]},{"cell_type":"markdown","metadata":{},"source":["# ðŸ“Œ Conclusion  \n","\n","After testing different sentiment classification models, we observed significant variations in accuracy:  \n","\n","- **Naive Bayes** achieved **22%** accuracy, indicating that the model struggled to capture meaningful patterns from the text.  \n","- **TF-IDF + Logistic Regression** also reached **22%**, suggesting that while TF-IDF is a more advanced vectorization method, logistic regression did not provide significant improvements in this case.  \n","- **Random Forest** achieved **42%** accuracy, making it the best-performing model among those tested. This suggests that it was better at capturing relationships between words and sentiments, even without using deep learning techniques.  \n","\n","## ðŸ’¡ Next Steps  \n","- Tune **hyperparameters** of the Random Forest model to explore potential improvements.  \n","- Test more advanced models, such as **neural networks (LSTM, Transformers)**, to see if they can surpass the **42%** accuracy.  \n","- Explore **data augmentation** and preprocessing techniques, such as removing irrelevant words, to enhance model performance.  \n","\n","ðŸš€ **Conclusion:** Random Forest emerged as the most effective model, but there is room for optimization and experimentation with more advanced approaches.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4245661,"sourceId":7316566,"sourceType":"datasetVersion"}],"dockerImageVersionId":30918,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
